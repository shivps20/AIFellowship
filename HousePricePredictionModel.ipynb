{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2263fa-4581-48a8-96d9-9456bc856b36",
   "metadata": {},
   "source": [
    "# Model to predict House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a1c6b-ae92-478b-9ce9-47b7507c1fe8",
   "metadata": {},
   "source": [
    "## Steps to perform the same\n",
    "1. Define the Problem Statement\n",
    "2. Prepare the Data\n",
    "3. Split the data into features and target values\n",
    "4. Normalize/Standardize the Features\n",
    "5. Split the data into training and testing\n",
    "6. Chose and Train the Model\n",
    "7. Make Predictions\n",
    "8. Evaluate the Model (Measure the error or loss)\n",
    "9. Adjust parameters (weight and bias) to reduce the error\n",
    "10. Repeat Steps 5 to 8, until the error is minimized (converged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d35bba-5ee8-4abd-97ff-220cce10ed22",
   "metadata": {},
   "source": [
    "### Define the Problem Statement\n",
    "\n",
    "The objective is to prepate the Model which can predict the price the House, for the given input parameters.\n",
    "Input Parametrs = Size (in Sq Ft), No of Bedrooms and City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23034425-0193-440c-ad79-e5498b125395",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80504b5d-788e-4240-ba3e-bf055fd83b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Size  Bedrooms       City   Price\n",
      "0  1000         2     Mumbai  200000\n",
      "1  1500         3  Bangalore  250000\n",
      "2  2000         4     Mumbai  310000\n",
      "3  1200         2       Pune  220000\n",
      "4  1800         3  Bangalore  290000\n",
      "5  1400         3     Mumbai  240000\n",
      "6  1600         3       Pune  270000\n",
      "7  1300         2     Mumbai  210000\n",
      "8  1700         3  Bangalore  280000\n",
      "9  1100         2       Pune  215000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'Size': [1000, 1500, 2000, 1200, 1800, 1400, 1600, 1300, 1700, 1100],\n",
    "    'Bedrooms': [2, 3, 4, 2, 3, 3, 3, 2, 3, 2],\n",
    "    'City': ['Mumbai', 'Bangalore', 'Mumbai', 'Pune', 'Bangalore', 'Mumbai', 'Pune', 'Mumbai', 'Bangalore', 'Pune'],\n",
    "    'Price': [200000, 250000, 310000, 220000, 290000, 240000, 270000, 210000, 280000, 215000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4908d9a-10c1-4527-8633-5f94708fb545",
   "metadata": {},
   "source": [
    "#### Encode the categorical feature (City)\n",
    "Why Do We Need to Encode Categorical Columns like City ? \n",
    "Machine learning models (especially linear regression, decision trees, SVM, etc.) work only with numerical values. They cannot directly understand text labels like \"Mumbai\", \"Pune\", or \"Bangalore\".\n",
    "\n",
    "Solution: Convert Categories to Numbers\n",
    "We use **One-Hot Encoding**, which:\n",
    "1. Creates a separate binary column for each city.\n",
    "2. Puts 1 where that city is present, 0 otherwise.\n",
    "\n",
    "We drop one column (City_Pune) using drop_first=True to avoid redundancy (called dummy variable trap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd824bbb-5749-470b-9901-6db2f13bea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Size  Bedrooms   Price  City_Mumbai  City_Pune\n",
      "0  1000         2  200000         True      False\n",
      "1  1500         3  250000        False      False\n",
      "2  2000         4  310000         True      False\n",
      "3  1200         2  220000        False       True\n",
      "4  1800         3  290000        False      False\n",
      "5  1400         3  240000         True      False\n",
      "6  1600         3  270000        False       True\n",
      "7  1300         2  210000         True      False\n",
      "8  1700         3  280000        False      False\n",
      "9  1100         2  215000        False       True\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['City'], drop_first=True)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf55e7c-1031-408d-9ac3-97a7c5044be8",
   "metadata": {},
   "source": [
    "### Split the data into features and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581a1ccc-4a21-4080-9ba4-e1a6ab292836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Data: \n",
      "    Size  Bedrooms  City_Mumbai  City_Pune\n",
      "0  1000         2         True      False\n",
      "1  1500         3        False      False\n",
      "2  2000         4         True      False\n",
      "3  1200         2        False       True\n",
      "4  1800         3        False      False\n",
      "5  1400         3         True      False\n",
      "6  1600         3        False       True\n",
      "7  1300         2         True      False\n",
      "8  1700         3        False      False\n",
      "9  1100         2        False       True\n",
      "\n",
      "\n",
      "\n",
      "Target Data: \n",
      " 0    200000\n",
      "1    250000\n",
      "2    310000\n",
      "3    220000\n",
      "4    290000\n",
      "5    240000\n",
      "6    270000\n",
      "7    210000\n",
      "8    280000\n",
      "9    215000\n",
      "Name: Price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded.drop('Price', axis=1) # axis=1 means \"drop column\" (not row). If you used axis=0, it would try to drop a row.\n",
    "Y = df_encoded['Price']\n",
    "print(f\"Features Data: \\n {X}\")\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Target Data: \\n {Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621e105-7f9b-4c81-8f4c-22b381cff726",
   "metadata": {},
   "source": [
    "### Normalize/Standardize the Features\n",
    "Normalization (or Standardization) ensures that all input features contribute equally to the model training — especially important when features are on different scales.\n",
    "\n",
    "**Problem Without Normalization:**\n",
    "\n",
    "Let’s say you have:  \n",
    "Size in 1000s (e.g., 1500, 2000, 2500)  \n",
    "Bedrooms in single digits (e.g., 2, 3, 4)\n",
    "\n",
    "If you don't normalize:  \n",
    "Size will dominate the learning process simply because its values are much larger.  \n",
    "The model may ignore smaller-scale features like Bedrooms, even if they matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2469657-6be5-4a36-84cb-cbb5aafadf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5132889  -1.09321633  1.22474487 -0.65465367]\n",
      " [ 0.13159034  0.46852129 -0.81649658 -0.65465367]\n",
      " [ 1.77646958  2.0302589   1.22474487 -0.65465367]\n",
      " [-0.8553372  -1.09321633 -0.81649658  1.52752523]\n",
      " [ 1.11851788  0.46852129 -0.81649658 -0.65465367]\n",
      " [-0.19738551  0.46852129  1.22474487 -0.65465367]\n",
      " [ 0.46056619  0.46852129 -0.81649658  1.52752523]\n",
      " [-0.52636136 -1.09321633  1.22474487 -0.65465367]\n",
      " [ 0.78954203  0.46852129 -0.81649658 -0.65465367]\n",
      " [-1.18431305 -1.09321633 -0.81649658  1.52752523]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Define the column transformer (OneHotEncoder for 'City', StandardScaler for numerical columns)\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('city', OneHotEncoder(), ['City']),  # OneHotEncoder for 'City'\n",
    "#         ('num', StandardScaler(), ['Size', 'Bedrooms'])  # StandardScaler for 'Size' and 'Bedrooms'\n",
    "#     ])\n",
    "\n",
    "# # Create a pipeline with preprocessing steps\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor)\n",
    "# ])\n",
    "\n",
    "# # # Fit and transform the features using the pipeline\n",
    "# X_scaled = pipeline.fit_transform(X)\n",
    "\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5484228-f0e3-4aac-80f9-69f1a0ba4139",
   "metadata": {},
   "source": [
    "### Split the data into Train and Test\n",
    "\n",
    "Splits data into:\n",
    "1. 80% for training <br>\n",
    "2. 20% for testing <br>\n",
    "random_state=42 ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d88a8d0-9ec3-49a3-b21d-dc83e2d761b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0febf1d5-141d-4406-a9f2-9d2b5fea66e7",
   "metadata": {},
   "source": [
    "### Chose and Train the Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
